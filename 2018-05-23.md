## Chosen paper

[Looking to Listen at the Cocktail Party: A Speaker-Independent Audio-Visual Model for Speech Separation](https://arxiv.org/abs/1804.03619), Ariel Ephrat, Inbar Mosseri, Oran Lang, Tali Dekel, Kevin Wilson, Avinatan Hassidim, William T. Freeman, Michael Rubinstein \[[blog](https://ai.googleblog.com/2018/04/looking-to-listen-audio-visual-speech.html)\] \[[video](https://www.youtube.com/watch?v=rVQVAPiJWKU)\] \[[webpage](https://looking-to-listen.github.io/)\]

## Other suggestions

* [Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style Transfer](https://arxiv.org/abs/1804.06437), Juncen Li, Robin Jia, He He, Percy Liang
* [Poincaré Embeddings for Learning Hierarchical Representations](http://papers.nips.cc/paper/7213-poincare-embeddings-for-learning-hierarchical-representations), Maximillian Nickel, Douwe Kiela
* [Attention is All You Need](http://papers.nips.cc/paper/7181-attention-is-all-you-need), Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin
